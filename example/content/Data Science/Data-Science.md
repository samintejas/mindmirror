# Data Science

Data science is the understanding of the world through the scientific analysis of digital data. **Data science** combines the scientific method, math and statistics, specialized programming, advanced analytics, artificial intelligence (AI), and even storytelling to uncover and explain the business insights buried in data. Data science is a **multidisciplinary approach** to extracting **actionable insights** from the large and ever-increasing volumes of data collected and created by today’s businesses. 

[25 Top Data Science Applications & Examples to Know | Built In](https://builtin.com/data-science/data-science-applications-examples)

In general, data professionals work everywhere! You’ll find them in large, global companies and mid-size organizations across industries, such as:

- Finance
- Insurance
- Healthcare
- Scientific services
- Information technology (IT)
- Marketing
- Management of companies
- Manufacturing
- Public administration
- Education services
- Arts and entertainment
- Retail

## Skills required for data scientist

- Data analysis
- Data science
- Machine learning
- Predictive models
- Artificial intelligence (AI)

- Communication skills
- Teamwork and collaboration
- Problem solving
- Research
- Creativity
- Writing
- Presentation skills

- SQL
- Python
- Tableau
- Additional tools and programming expertise, such as R, Apache Hadoop, TensorFlow, Scala, Scikit-learn, and more

**The 5 Whys**

When analyzing data, you’ll find a problem and need to understand why. The [5 Whys(opens in a new tab)](https://en.wikipedia.org/wiki/Five_whys) is a valuable technique in problem solving that is easy to remember. You can determine the root cause of a problem by **asking the question "Why?" five times**.

![https://ole03.yourlearning.ibm.com/pluginfile.php/99985/mod_scorm/content/6/scormcontent/assets/7FGBweMdF6SPli2P_ADROeFHvMOR7IsJd.png](https://ole03.yourlearning.ibm.com/pluginfile.php/99985/mod_scorm/content/6/scormcontent/assets/7FGBweMdF6SPli2P_ADROeFHvMOR7IsJd.png)

![https://ole03.yourlearning.ibm.com/pluginfile.php/99985/mod_scorm/content/6/scormcontent/assets/7FGBweMdF6SPli2P_ADROeFHvMOR7IsJd.png](https://ole03.yourlearning.ibm.com/pluginfile.php/99985/mod_scorm/content/6/scormcontent/assets/7FGBweMdF6SPli2P_ADROeFHvMOR7IsJd.png)

![https://ole03.yourlearning.ibm.com/pluginfile.php/99985/mod_scorm/content/6/scormcontent/assets/7FGBweMdF6SPli2P_ADROeFHvMOR7IsJd.png](https://ole03.yourlearning.ibm.com/pluginfile.php/99985/mod_scorm/content/6/scormcontent/assets/7FGBweMdF6SPli2P_ADROeFHvMOR7IsJd.png)

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled.png)

## Data

**Structured data**

Structured data is information that can be organized in rows and columns. Perhaps you've seen structured data in a spreadsheet, like Google Sheets or Microsoft Excel. For complex information, data analysts use tools like Structured Query Language (SQL) which can sort through vast amounts of data stored in many connected tables. If you can organize information within data into groups, based on specific characteristics, then those groups are structured data.

**Unstructured data**

Unstructured data refers to “everything else”. There is no predefined format. Unstructured data lacks any built-in organization, or structure. It’s a conglomeration of varied types of data that are stored in their original formats.  

Another way to distinguish data is 

Quantitative data:

- Is also called **numerical data**
- Represents things that can be measured and assigned values
- Can be counted and measured, such as height, weight, length, blood pressure, the temperature outside, and so on

Qualitative data:

- Is also called **categorical data**
- Represents the characteristics, attributes, properties, and qualities of things
- Describes data using language (rather than numbers), such as smell, location, color, texture, marital status, and so on

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled%201.png)

## BigData

The elements of big data can be explained using five broad characteristics called the **5 V’s**. The 5 V’s are **Volume**, **Variety**, **Velocity**, **Veracity**, and **Value**. ****The 5 V’s help data scientists make sense of what they are working with and are depicted in this diagram.

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled%202.png)

## Data Analytics Types

- Descriptive analytics
- Diagnostic analytics
- Predictive analytics
- Prescriptive analytics

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled%203.png)

Descriptive analytics answers the question, “What is happening?”. It provides a snapshot of business trends and patterns and uses historical and current data.

After asking the question, “What is happening?”, the next step is to dive deeper and ask “why?”, such as,  “Why are trends and patterns happening?” This is where diagnostic analytics comes in.Diagnostic analytics takes the insights found from descriptive analytics and drills down to find the causes of specific problems.

Predictive analytics is about forecasting. This type of analytics uses historical data to make predictions about the future. Whether it’s the likelihood of a future event, forecasting a quantifiable amount, or estimating a point in time at which something might happen – these are all done through predictive models.

Prescriptive analytics combines the insight from all previous data analyses to determine a course of action to take to address a problem or make a decision.The purpose of prescriptive analytics is to prescribe what action to take to eliminate a future problem or take full advantage of a promising trend.

## DS Methodologies

A **methodology** is a general strategy that guides activities within a process. A methodology doesn’t depend on technologies or tools, and it’s not a set of techniques or recipes. 
Rather, a methodology provides data scientists with a **framework** for how to proceed with whatever methods and processes they will use to **obtain answers or results**.
**three classic and widely adopted data science methodologies**:

- Cross-Industry Standard Process for Data Mining (CRISP-DM)
- Knowledge Discovery in Database (KDD)
- Sample, Explore, Modify, Model, Assess (SEMMA).

these methodologies are usefull for 

- Use data mining methods
- Are best suited for structured data
- Are useful for using descriptive and predictive analytics
- Share some common activities, such as data gathering, data transformation, data modeling, and model evaluation

## **CRISP-DM**

![https://ole03.yourlearning.ibm.com/pluginfile.php/99985/mod_scorm/content/6/scormcontent/assets/3u4SqPpTqYsslWQw_k4mzjIIjMh-ubQ1g.jpg](https://ole03.yourlearning.ibm.com/pluginfile.php/99985/mod_scorm/content/6/scormcontent/assets/3u4SqPpTqYsslWQw_k4mzjIIjMh-ubQ1g.jpg)

**Cross-Industry Standard Process for Data Mining.**

CRISP-DM consists of six phases with arrows indicating the most important and frequent dependencies between phases:

1. Business understanding
2. Data understanding
3. Data preparation
4. Modeling
5. Evaluation
6. Deployment

The sequence of the phases is not strict. CRISP-DM is **iterative**, meaning that the phases can be repeated to incrementally improve the 
result. The results of some stages might require the project cycle to go back to earlier stages.

## KDD

KDD stands for **Knowledge Discovery in Database.** 

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled.jpeg)

KDD represents the overall process of collecting data and methodically refining it. KDD typically has five steps:

1. Selection
2. Preprocessing
3. Transformation
4. Data Mining
5. Interpretation/Evaluation

The KDD methodology can help businesses stay current with customer needs and behaviors and predict future purchasing trends to stay competitive. But, the process doesn’t address many of the modern realities of data science projects, such as the setup of big data architecture, considerations of ethics, or the various roles in a data science team.

KDD is **iterative**, meaning new data can be integrated and transformed to get different and more appropriate results. The knowledge acquired can be cycled back into the process, enhancing its effectiveness.

## SEMMA

SEMMA stands for its five steps:

1. **S**ample
2. **E**xplore
3. **M**odify
4. **M**odel
5. **A**ssess

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled%201.jpeg)

SEMMA is a data science methodology that helps convert data into knowledge. SEMMA can help solve a range of business problems, such as fraud identification, customer retention and turnover, database marketing, customer loyalty, market segmentation, and risk analysis.

SEMMA is also an **iterative** process, in which answering one set of questions often leads to more interesting and more specific questions.

## **business understanding**

Every project, regardless of how big it is, starts with **business understanding**. Before any data exploration can be done, the team must understand the problem that needs to be solved.

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled%202.jpeg)

As part of this method, the data science project team might host a design thinking workshop and apply techniques to:

- Define the problem
- Determine the project objectives
- Develop personas or fictional characters that represent typical end users
- Document solution requirements from a business perspective

Once the business problem is clearly stated, a **data scientist** on the team defines the analytic approach to solving the problem. This involves expressing the problem in the context of statistical and machine learning techniques. For example, if the goal is to predict a customer’s response in terms of a “yes” or a “no”, then the analytic approach could be defined as building, testing, and implementing something called a logistical regression model. Data scientists are experts who have many technologies and methods in their toolbox!

## **Data exploration and preparation**

Data scientists identify and collect data from existing and often new sources in a business. This could be structured and unstructured data that is relevant to the problem. They might retrieve data from sources such as:

- Static files, such as spreadsheets
- Databases
- The internet

Here are a few questions a data scientist might think about during the initial exploration of data:

- Which data characteristics seem promising for further analysis?
- Has exploring revealed new characteristics about the data?
- Has exploring changed the initial hypothesis?

Next, the data scientist next **prepares the data**. Data preparation is very important and the most time-consuming step in a data science project. It involves constructing the data set that will be used in the modeling step. Data preparation also includes cleaning the data, combining data from multiple sources, and making sure the data doesn’t have any gaps. Additionally, data preparation includes cleaning or “wrangling” the data so it’s ready to transform. 

Data scientists can’t assume that data is ready to use, even if it’s structured data. Real-world data usually needs some work because it might be:

- Incomplete or have incorrect values
- Corrupted with broken lines or have fields in the wrong place
- Too random
- Irrelevant
- An outlier, which is a value that lies far away from other values and will skew the data
- A missing value in some fields

## **Data representation and transformation**

The data representation and transformation step in the data science methodology is about:

- Understanding the data
- Assessing data quality
- Discovering initial insights about the data

Descriptive statistics, visualization techniques, and many other techniques help data scientists understand data and **assess its quality**. Data science teams must validate the quality of the data they use as input for predictive modeling because poor quality data will lead to poor model performance later in the process. 

**Descriptive statistics**

To understand data, a data scientist can use a mathematical approach, such as descriptive statistics. **Descriptive statistics** quantitatively summarizes a data set. It can answer the question, “What is happening?” Data scientists can build a table to describe a large, complex data set and make quick observations about:

- Number (N): What is the total number of observations?
- Mean: What is the average of a set of two or more numbers?
- Median: What is the middle number or “center” in a sorted list of numbers?
- Mode: What is the most observed value in a data set?
- Minimum: What is the minimum extreme of a data set?
- Maximum: What is the maximum extreme of a data set?
- Standard deviation: How spread out is the data in relation to the mean?

## **Data visualization and presentation**

**Data visualization** is the culmination of a data science team’s efforts to view the insights that their data transformation efforts have produced. 

A famous data visualization 

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled%203.jpeg)

There are many types of visualization , like pie chart , column bar , line graphs , scatter plots etc

![Untitled](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Untitled%204.png)

[From data to Viz | Find the graphic you need](https://www.data-to-viz.com/)

The final **data presentation** must be meaningful, compelling, and, most importantly, easy to interpret for the business sponsor. A team's presentation design must go beyond just showing results and the look of the data visualization or visualizations. The team must consider the:

- **Purpose**: What problem are you trying to address and why will data visualization help to solve it?
- **Audience**: Who is viewing the presentation and how can it be valuable to them?
- **Data**: Is the data represented in the best way and will the visualization need to be updated in the future?
- **Context**: Where will the visualization reside (for example, in software, on a website, or in a business report)?

## **Train data models**

A data model identifies the data, data attributes, and relationships or associations with other data. A data model provides a generalized view of data that represents the real business scenario and data. 

**Why build a model?** A data scientist can develop a more systematic approach to address an identified business problem by building a model. The main goal of building a model is to make better predictions for the business and gain a better understanding of the system being modeled.

Machine learning is used to model data 

Here are three methods for machine learning, based on the algorithms used and the results that are required.

**supervised learning**

In supervised learning, a machine ingests many questions and their answers—essentially a set of pre-structured information. The information might, for example, be drawings and photos of animals, some of which are dogs and are labeled “dog”. The machine attempts to  identify patterns so that when it sees a new photo of a dog and is asked, “What is this?”, it can respond, “dog”, with high accuracy.

Supervised learning trains machines on data to build general rules that can be applied to future problems. The better the training set of data, the better the output.

**unsupervised learning**

In unsupervised learning, a machine ingests an enormous amount of information, asked a question, then allowed to determine how to answer the question by itself. For example, a machine might receive many photos and articles about dogs. The machine ingests and classifies the information within all of the photos and articles. When the machine is shown a new photo of a dog, the machine is intended to be able to identify it as a dog, with reasonable accuracy.

Unsupervised learning trains machines on a huge volume of unlabeled or unstructured data.

**Reinforcement learning**

Humans and machines can learn through reinforcement learning. Reinforcement learning is a feedback-based, machine-learning technique. Through reinforcement learning, a machine determines how to behave in an environment by performing and observing the results of its actions. For each “good” action, the machine receives positive feedback (a reward). For each “bad” action, the machine receives negative feedback (a penalty). As a result, the machine learns automatically, through its experience and feedback.

Reinforcement learning doesn’t involve a specific goal. Rather, it involves learning from trial and error or “learn as you go”. Reinforcement learning is widely used in self-driven cars, drones, and other robotics applications.

[Tools used for DS](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Tools%20used%20for%20DS%2015ef2bb0895548b2bb7dd4eb77fd3aa6.md)

[Notable Orgs](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Notable%20Orgs%2054bf50ec63b64fbfb8dfc024a926465e.md)

[Publications](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Publications%2019043713e4c642079093d2789ca558e5.md)

[News and blogs](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/News%20and%20blogs%2029e6581e55c74bd99d6ad33bb7e9d4ee.md)

[Learning resources](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Learning%20resources%2006cf41bab5e84731abaf1c9de4d4b8fd.md)

[Certification](Data%20Science%20bcb35b73763d4e27a8383b5b4293c4ca/Certification%20c70f563c03e9403ca00d072d48e4007e.md)